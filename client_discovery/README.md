# 🔍 고객사 발굴 자동화 시스템

네이버 쇼핑을 통한 타겟 고객사 자동 발굴 RPA 시스템

## ✨ 주요 기능

- **자동 크롤링**: 네이버 쇼핑에서 키워드 기반 스토어 검색
- **스마트 필터링**: 리뷰 수, 관심고객 수 기반 타겟 선별
- **안전 장치**: 캡챠/탐지 시 자동 중단, 정책 준수
- **결과 저장**: CSV 형태로 타겟 고객사 리스트 저장
- **GUI 통합**: 기존 콜드메일 시스템과 완벽 연동

## 🚀 사용 방법

### 1. GUI에서 실행 (권장)
1. 메인 프로그램 실행
2. "🔍 고객사 발굴" 탭 클릭
3. 검색 조건 설정:
   - **검색 키워드**: 찾고자 하는 상품 (예: "텀블러")
   - **리뷰 범위**: 200~300개 (조정 가능)
   - **관심고객**: 50~1500명 (조정 가능)
   - **최대 방문**: 500개 스토어 (조정 가능)
4. "🔍 크롤링 시작" 버튼 클릭
5. 실시간 로그 확인
6. 완료 후 "📊 결과 보기"로 CSV 파일 확인

### 2. 직접 실행
```python
from client_discovery.main_crawler import run_crawler
result = run_crawler()
```

## 📁 파일 구조

```
client_discovery/
├── __init__.py              # 패키지 초기화
├── config.json              # 크롤링 설정
├── models.py                # 데이터 모델
├── utils.py                 # 공통 유틸리티
├── main_crawler.py          # 메인 크롤러
├── m1_ui_navigator.py       # UI 진입 & 정렬
├── m2_list_scanner.py       # 리스트 스캐너
├── m3_detail_reader.py      # 상세 정보 추출
├── m4_filter.py             # 필터링 & 중복 제거
├── m5_storage.py            # 저장 & 체크포인트
├── m6_monitor.py            # 안전 감시
├── assets/img/              # 앵커 이미지 (설정 필요)
├── screens/                 # 스크린샷 저장
├── targets_YYYYMMDD.csv     # 결과 파일
└── checkpoint.json          # 중단 시 재개 정보
```

## ⚙️ 설정

### config.json 주요 설정
```json
{
  "search": {
    "keyword": "텀블러",
    "review_min": 200,
    "review_max": 300,
    "follower_min": 50,
    "follower_max": 1500,
    "max_visits_per_run": 500
  },
  "blocklist": [
    "쿠팡", "11번가", "G마켓", "옥션", "SSG", "롯데ON", "카카오"
  ]
}
```

### 필수 앵커 이미지 (수동 준비 필요)
다음 이미지들을 `assets/img/` 폴더에 준비해주세요:

1. **tab_shoppingmall.png**: 쇼핑몰/스토어 탭 버튼
2. **sort_review_desc.png**: "리뷰 많은순" 정렬 버튼
3. **label_review.png**: 리뷰 수 텍스트 라벨
4. **label_interest.png**: 관심고객 수 텍스트 라벨

> 💡 **앵커 이미지 제작 팁**:
> - 해상도 1920x1080, 브라우저 줌 100%에서 스크린샷
> - 각 요소별로 2-3개 변형 이미지 준비 권장
> - PNG 형식, 배경 투명 불필요

## 🛡️ 안전 장치

- **캡챠 감지**: 자동으로 중단하고 스크린샷 저장
- **중복 제거**: URL/이름 기반 3단계 중복 방지
- **속도 제한**: 자연스러운 브라우징 패턴 유지
- **ESC 중단**: 언제든 ESC 키로 즉시 중단 가능
- **체크포인트**: 중단 시 마지막 위치에서 재개 가능

## 📊 결과 파일

### CSV 형태 (targets_YYYYMMDD.csv)
```csv
collected_at,store_name,store_url,review_count,interest_count,note
2024-01-15 14:30:25,ABC스토어,https://...,250,120,
2024-01-15 14:31:10,XYZ샵,https://...,280,95,
```

### 통계 로그 (run.log)
```
=== 실행 로그 2024-01-15 14:35:00 ===
총 방문: 45
저장: 12
스킵:
  - 리뷰 범위 외: 15
  - 관심고객 범위 외: 10
  - 차단 목록: 5
  - 중복: 3
오류: 0
종료 사유: 정상 완료
```

## 🔄 기존 시스템 연동

발굴된 고객사 리스트는 다음과 같이 활용 가능:

1. **타겟 선정**: CSV에서 우선순위 고객사 선별
2. **상품 수집**: 선별된 고객사 상품 이미지 수집
3. **콜드메일 생성**: 기존 AI 시스템으로 개인화 메일 작성
4. **발송 관리**: Excel 기반 발송 상태 관리

## ⚠️ 주의사항

- **네이버 정책 준수**: 과도한 요청 금지
- **수동 개입**: 의심 상황 발생 시 즉시 중단
- **환경 고정**: 해상도/줌/테마 변경 시 앵커 이미지 재설정
- **백업**: 중요한 결과는 별도 백업 권장

## 🛠️ 필요 라이브러리

```
pyautogui>=0.9.54
pyperclip>=1.8.2
opencv-python>=4.8.0
pytesseract>=0.3.10  # OCR 기능 (선택사항)
pygetwindow>=0.0.9
keyboard>=0.13.5
pandas>=2.0.0
pathlib
```

## 📞 문제 해결

### 일반적인 문제들

1. **앵커 이미지 인식 실패**
   - 해상도/줌 설정 확인
   - 앵커 이미지 재촬영

2. **OCR 정확도 낮음**
   - Tesseract 설치 확인
   - 한글 언어팩 설치

3. **의심 화면 감지**
   - 잠시 대기 후 재시도
   - 수동으로 브라우저 새로고침

4. **결과 파일 없음**
   - 필터 조건 완화
   - 다른 키워드로 시도

### 로그 확인 방법
- GUI: 실시간 로그 패널
- 파일: `client_discovery/run.log`
- 스크린샷: `client_discovery/screens/`

---

💡 **더 자세한 도움이 필요하시면 GUI의 로그를 확인하거나 개발팀에 문의하세요.**